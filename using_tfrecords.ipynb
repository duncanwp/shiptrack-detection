{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d4a8697",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-13 17:45:52.554190: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n",
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "from shiptrack import get_data, get_preprocessing, losses, fit_model\n",
    "from segmentation_models import get_preprocessing\n",
    "from segmentation_models import Unet\n",
    "from segmentation_models.metrics import iou_score\n",
    "import glob\n",
    "    \n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c280c09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "epochs = 30\n",
    "batch_size = 8\n",
    "learning_rate = 0.01\n",
    "augment = False\n",
    "encoder_freeze = False\n",
    "backbone = \"resnet152\"\n",
    "test_prop = 5\n",
    "loss = \"bce_jaccard_loss\"\n",
    "\n",
    "INT_IMG_SIZE = (2240, 1344)\n",
    "IMG_SIZE = 448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11511fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "\n",
    "model_name = f\"{now.strftime('%Y%m%d_%H%M%S')}_new_{backbone}_{loss}{'_augmented' if augment else ''}\"\n",
    "# System paths\n",
    "training_dir = \"/lustre_scratch/duncanwp/combined_v3_typed_new_composite\"\n",
    "tensorboard_dir = f\"/lustre_scratch/duncanwp/tensorboard/{model_name}\"\n",
    "model_dir = f\"/lustre_scratch/duncanwp/models/{model_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "059bf678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-13 17:46:11.253298: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-13 17:46:11.423931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:07:00.0 name: Tesla V100-SXM2-32GB-LS computeCapability: 7.0\n",
      "coreClock: 1.44GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 772.48GiB/s\n",
      "2021-07-13 17:46:11.428393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:0a:00.0 name: Tesla V100-SXM2-32GB-LS computeCapability: 7.0\n",
      "coreClock: 1.44GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 772.48GiB/s\n",
      "2021-07-13 17:46:11.443451: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-13 17:46:11.768413: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-13 17:46:11.768620: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-07-13 17:46:11.881440: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-07-13 17:46:12.021058: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-07-13 17:46:12.069288: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-07-13 17:46:12.147932: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-07-13 17:46:12.168173: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-07-13 17:46:12.177748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1\n",
      "2021-07-13 17:46:12.219231: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-13 17:46:12.622620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:07:00.0 name: Tesla V100-SXM2-32GB-LS computeCapability: 7.0\n",
      "coreClock: 1.44GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 772.48GiB/s\n",
      "2021-07-13 17:46:12.626034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:0a:00.0 name: Tesla V100-SXM2-32GB-LS computeCapability: 7.0\n",
      "coreClock: 1.44GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 772.48GiB/s\n",
      "2021-07-13 17:46:12.639138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1\n",
      "2021-07-13 17:46:12.675281: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-13 17:46:15.214741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-13 17:46:15.214799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 1 \n",
      "2021-07-13 17:46:15.214809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N Y \n",
      "2021-07-13 17:46:15.214815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 1:   Y N \n",
      "2021-07-13 17:46:15.236682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30957 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB-LS, pci bus id: 0000:07:00.0, compute capability: 7.0)\n",
      "2021-07-13 17:46:15.289495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 30957 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB-LS, pci bus id: 0000:0a:00.0, compute capability: 7.0)\n"
     ]
    }
   ],
   "source": [
    "def create_mixed_dataset(training_dir, shuffle_size=1024, balance=None):\n",
    "# Balance should be a tuple of shape (2, ) describing the positive/negative weighting\n",
    "    positive = create_dataset(training_dir, shuffle_size=shuffle_size, cls_label='positive')\n",
    "    negative = create_dataset(training_dir, shuffle_size=shuffle_size, cls_label='negative')\n",
    "    if balance is None:\n",
    "        balance = (0.5, 0.5)\n",
    "    sampled_ds=tf.data.experimental.sample_from_datasets(datasets, weights=balance)\n",
    "    return sampled_ds\n",
    "\n",
    "# Note, if we wanted fewer classes, we can use glob syntax to grab multiple classes as once\n",
    "# e.g. create_dataset(2015,\"[67]\")\n",
    "# will take classes 6 & 7 together\n",
    "\n",
    "def _parse_batch(record_batch):\n",
    "    # Create a description of the features\n",
    "    feature_description = {\n",
    "        'data': tf.io.FixedLenFeature((IMG_SIZE, IMG_SIZE, 3), tf.float32),\n",
    "        'mask': tf.io.FixedLenFeature((IMG_SIZE, IMG_SIZE), tf.float32),\n",
    "    }\n",
    "\n",
    "    # Parse the input `tf.Example` proto using the dictionary above\n",
    "    example = tf.io.parse_example(record_batch, feature_description)\n",
    "    return example['data'], example['mask']\n",
    "\n",
    "\n",
    "def create_dataset(training_dir, shuffle_size=1024, cls_label='positive'):\n",
    "\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    fl = glob.glob(f\"/{training_dir}/tfrecords/*_{cls_label}.tfrecords\")\n",
    "    files_ds = tf.data.Dataset.list_files(fl)\n",
    "    ds = tf.data.TFRecordDataset(files_ds, num_parallel_reads=AUTOTUNE)\n",
    "    ds = ds.shuffle(shuffle_size)\n",
    "    ds = ds.map(lambda x: _parse_batch(x))\n",
    "    return ds\n",
    "\n",
    "\n",
    "ds_size = len(list(glob.glob(f\"/{training_dir}/tfrecords/*_positive.tfrecords\"))) # This assumes only taking positive examples\n",
    "ds = create_dataset(training_dir)\n",
    "\n",
    "train_split=0.8\n",
    "val_split=0.1\n",
    "test_split=0.1\n",
    "train_size = int(train_split * ds_size)\n",
    "val_size = int(val_split * ds_size)\n",
    "\n",
    "train_ds = ds.take(train_size)    \n",
    "val_ds = ds.skip(train_size).take(val_size)\n",
    "test_ds = ds.skip(train_size).skip(val_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05ea5c80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "# Automatically mirror training across all available GPUs\n",
    "strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
    "with strategy.scope():\n",
    "\n",
    "    model = Unet(backbone, encoder_weights='imagenet', encoder_freeze=encoder_freeze,\n",
    "                 classes=1, activation='sigmoid')\n",
    "\n",
    "#     print(model.summary())\n",
    "\n",
    "    model.compile(Adam(learning_rate=learning_rate), loss=losses[loss], metrics=[iou_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ece2aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-13 17:46:25.375062: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-07-13 17:46:25.375108: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2021-07-13 17:46:25.392996: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1611] Profiler found 2 GPUs\n",
      "2021-07-13 17:46:25.579014: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcupti.so.11.2\n",
      "2021-07-13 17:46:25.951317: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2021-07-13 17:46:25.963401: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard, ReduceLROnPlateau\n",
    "tensorboard = TensorBoard(log_dir=tensorboard_dir, histogram_freq=0,\n",
    "                          write_images=True, write_graph=False)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=5e-7, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fee005ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def get_data_flow(data, labels, subset, batch_size=1):\n",
    "#     # this is the augmentation configuration we will use for training\n",
    "#     from keras.preprocessing.image import ImageDataGenerator\n",
    "#     datagen = ImageDataGenerator(\n",
    "#         shear_range=0.2,\n",
    "#         zoom_range=0.2,\n",
    "#         horizontal_flip=True,\n",
    "#         validation_split=0.2)\n",
    "#     generator = datagen.flow(\n",
    "#         data, y=labels,\n",
    "#         batch_size=batch_size if subset == 'training' else 1,\n",
    "#         subset=subset)\n",
    "#     return generator\n",
    "\n",
    "def get_data_flow(data, labels, subset, batch_size=1):\n",
    "    # we create two instances with the same arguments\n",
    "    data_gen_args = dict(\n",
    "                         shear_range=0.2,\n",
    "                         zoom_range=0.2,\n",
    "                         horizontal_flip=True,\n",
    "                        )\n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    # Provide the same seed and keyword arguments to the fit and flow methods\n",
    "    seed = 1\n",
    "    image_datagen.fit(data, augment=True, seed=seed)\n",
    "    mask_datagen.fit(labels, augment=True, seed=seed)\n",
    "    image_generator = image_datagen.flow(\n",
    "        data,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        seed=seed)\n",
    "    mask_generator = mask_datagen.flow(\n",
    "        labels,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        seed=seed)\n",
    "    # combine generators into one which yields image and masks\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    return train_generator\n",
    "\n",
    "if augment:\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06e9a4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "      1/Unknown - 5s 5s/step - loss: 1.0010 - iou_score: 0.1565"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-13 18:27:12.067429: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-07-13 18:27:12.067483: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2/Unknown - 6s 2s/step - loss: 0.9294 - iou_score: 0.1936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-13 18:27:14.447324: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-07-13 18:27:14.461945: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed\n",
      "2021-07-13 18:27:14.619332: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 7572 callback api events and 7569 activity events. \n",
      "2021-07-13 18:27:14.799429: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2021-07-13 18:27:15.026689: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /lustre_scratch/duncanwp/tensorboard/20210713_174611_new_resnet152_bce_jaccard_loss/train/plugins/profile/2021_07_13_18_27_14\n",
      "2021-07-13 18:27:15.155219: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to /lustre_scratch/duncanwp/tensorboard/20210713_174611_new_resnet152_bce_jaccard_loss/train/plugins/profile/2021_07_13_18_27_14/jupyter-duncanwp.trace.json.gz\n",
      "2021-07-13 18:27:15.436089: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /lustre_scratch/duncanwp/tensorboard/20210713_174611_new_resnet152_bce_jaccard_loss/train/plugins/profile/2021_07_13_18_27_14\n",
      "2021-07-13 18:27:15.461269: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to /lustre_scratch/duncanwp/tensorboard/20210713_174611_new_resnet152_bce_jaccard_loss/train/plugins/profile/2021_07_13_18_27_14/jupyter-duncanwp.memory_profile.json.gz\n",
      "2021-07-13 18:27:15.486822: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /lustre_scratch/duncanwp/tensorboard/20210713_174611_new_resnet152_bce_jaccard_loss/train/plugins/profile/2021_07_13_18_27_14Dumped tool data for xplane.pb to /lustre_scratch/duncanwp/tensorboard/20210713_174611_new_resnet152_bce_jaccard_loss/train/plugins/profile/2021_07_13_18_27_14/jupyter-duncanwp.xplane.pb\n",
      "Dumped tool data for overview_page.pb to /lustre_scratch/duncanwp/tensorboard/20210713_174611_new_resnet152_bce_jaccard_loss/train/plugins/profile/2021_07_13_18_27_14/jupyter-duncanwp.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to /lustre_scratch/duncanwp/tensorboard/20210713_174611_new_resnet152_bce_jaccard_loss/train/plugins/profile/2021_07_13_18_27_14/jupyter-duncanwp.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to /lustre_scratch/duncanwp/tensorboard/20210713_174611_new_resnet152_bce_jaccard_loss/train/plugins/profile/2021_07_13_18_27_14/jupyter-duncanwp.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to /lustre_scratch/duncanwp/tensorboard/20210713_174611_new_resnet152_bce_jaccard_loss/train/plugins/profile/2021_07_13_18_27_14/jupyter-duncanwp.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277/277 [==============================] - 150s 528ms/step - loss: 0.8831 - iou_score: 0.1936 - val_loss: nan - val_iou_score: 0.1826\n",
      "Epoch 2/30\n",
      "277/277 [==============================] - 142s 509ms/step - loss: 0.8774 - iou_score: 0.1986 - val_loss: nan - val_iou_score: 0.1951\n",
      "Epoch 3/30\n",
      "277/277 [==============================] - 143s 513ms/step - loss: 0.8709 - iou_score: 0.2052 - val_loss: nan - val_iou_score: 0.2006\n",
      "Epoch 4/30\n",
      "277/277 [==============================] - 142s 510ms/step - loss: 0.8658 - iou_score: 0.2099 - val_loss: nan - val_iou_score: 0.1910\n",
      "Epoch 5/30\n",
      "277/277 [==============================] - 141s 507ms/step - loss: 0.8660 - iou_score: 0.2098 - val_loss: nan - val_iou_score: 0.2087\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 6/30\n",
      "277/277 [==============================] - 141s 508ms/step - loss: 0.8579 - iou_score: 0.2164 - val_loss: nan - val_iou_score: 0.1964\n",
      "Epoch 7/30\n",
      "277/277 [==============================] - 141s 506ms/step - loss: 0.8610 - iou_score: 0.2128 - val_loss: nan - val_iou_score: 0.1958\n",
      "Epoch 8/30\n",
      "277/277 [==============================] - 142s 507ms/step - loss: 0.8584 - iou_score: 0.2159 - val_loss: nan - val_iou_score: 0.2124\n",
      "Epoch 9/30\n",
      "277/277 [==============================] - 141s 506ms/step - loss: 0.8536 - iou_score: 0.2209 - val_loss: nan - val_iou_score: 0.2148\n",
      "Epoch 10/30\n",
      "277/277 [==============================] - 142s 508ms/step - loss: 0.8558 - iou_score: 0.2175 - val_loss: nan - val_iou_score: 0.2098\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Epoch 11/30\n",
      "277/277 [==============================] - 142s 508ms/step - loss: 0.8510 - iou_score: 0.2220 - val_loss: nan - val_iou_score: 0.2218\n",
      "Epoch 12/30\n",
      "277/277 [==============================] - 141s 507ms/step - loss: 0.8534 - iou_score: 0.2205 - val_loss: nan - val_iou_score: 0.2081\n",
      "Epoch 13/30\n",
      "277/277 [==============================] - 141s 507ms/step - loss: 0.8520 - iou_score: 0.2216 - val_loss: nan - val_iou_score: 0.2131\n",
      "Epoch 14/30\n",
      "277/277 [==============================] - 142s 508ms/step - loss: 0.8527 - iou_score: 0.2217 - val_loss: nan - val_iou_score: 0.2154\n",
      "Epoch 15/30\n",
      "277/277 [==============================] - 141s 506ms/step - loss: 0.8528 - iou_score: 0.2209 - val_loss: nan - val_iou_score: 0.1948\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "Epoch 16/30\n",
      "277/277 [==============================] - 141s 507ms/step - loss: 0.8521 - iou_score: 0.2214 - val_loss: nan - val_iou_score: 0.2115\n",
      "Epoch 17/30\n",
      "277/277 [==============================] - 141s 505ms/step - loss: 0.8534 - iou_score: 0.2204 - val_loss: nan - val_iou_score: 0.2133\n",
      "Epoch 18/30\n",
      "277/277 [==============================] - 141s 506ms/step - loss: 0.8522 - iou_score: 0.2212 - val_loss: nan - val_iou_score: 0.2137\n",
      "Epoch 19/30\n",
      "277/277 [==============================] - 141s 506ms/step - loss: 0.8487 - iou_score: 0.2240 - val_loss: nan - val_iou_score: 0.2020\n",
      "Epoch 20/30\n",
      "277/277 [==============================] - 141s 507ms/step - loss: 0.8525 - iou_score: 0.2212 - val_loss: nan - val_iou_score: 0.2013\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 3.199999628122896e-06.\n",
      "Epoch 21/30\n",
      "277/277 [==============================] - 141s 505ms/step - loss: 0.8530 - iou_score: 0.2216 - val_loss: nan - val_iou_score: 0.2084\n",
      "Epoch 22/30\n",
      "277/277 [==============================] - 141s 506ms/step - loss: 0.8537 - iou_score: 0.2209 - val_loss: nan - val_iou_score: 0.2102\n",
      "Epoch 23/30\n",
      "277/277 [==============================] - 141s 506ms/step - loss: 0.8524 - iou_score: 0.2197 - val_loss: nan - val_iou_score: 0.2223\n",
      "Epoch 24/30\n",
      "277/277 [==============================] - 141s 506ms/step - loss: 0.8529 - iou_score: 0.2208 - val_loss: nan - val_iou_score: 0.2173\n",
      "Epoch 25/30\n",
      "277/277 [==============================] - 141s 506ms/step - loss: 0.8495 - iou_score: 0.2237 - val_loss: nan - val_iou_score: 0.2277\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 6.399999165296323e-07.\n",
      "Epoch 26/30\n",
      "277/277 [==============================] - 141s 507ms/step - loss: 0.8505 - iou_score: 0.2226 - val_loss: nan - val_iou_score: 0.2160\n",
      "Epoch 27/30\n",
      "277/277 [==============================] - 141s 506ms/step - loss: 0.8552 - iou_score: 0.2186 - val_loss: nan - val_iou_score: 0.2129\n",
      "Epoch 28/30\n",
      "277/277 [==============================] - 142s 510ms/step - loss: 0.8530 - iou_score: 0.2207 - val_loss: nan - val_iou_score: 0.2203\n",
      "Epoch 29/30\n",
      "277/277 [==============================] - 141s 505ms/step - loss: 0.8515 - iou_score: 0.2223 - val_loss: nan - val_iou_score: 0.2145\n",
      "Epoch 30/30\n",
      "277/277 [==============================] - 141s 507ms/step - loss: 0.8478 - iou_score: 0.2249 - val_loss: nan - val_iou_score: 0.1921\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 5e-07.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds.shuffle(1024).batch(8*2).prefetch(tf.data.AUTOTUNE), validation_data=val_ds.prefetch(tf.data.AUTOTUNE), verbose=1,\n",
    "                    epochs=epochs, callbacks=[tensorboard, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcb3931a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SkipDataset shapes: ((448, 448, 3), (448, 448)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4842ac9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, None, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 3), dtype=tf.float32, name='data'), name='data', description=\"created by layer 'data'\"), but it was called on an input with incompatible shape (224, 448, 3).\n",
      "INFO:tensorflow:Error reported to Coordinator: Input 0 of layer bn_data is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: (224, 448, 3)\n",
      "Traceback (most recent call last):\n",
      "  File \"/lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\n",
      "    yield\n",
      "  File \"/lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_run.py\", line 334, in run\n",
      "    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n",
      "  File \"/lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 692, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"/lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 382, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 463, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\", line 1307, in run_step\n",
      "    outputs = model.test_step(data)\n",
      "  File \"/lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\", line 1266, in test_step\n",
      "    y_pred = self(x, training=False)\n",
      "  File \"/lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1030, in __call__\n",
      "    outputs = call_fn(inputs, *args, **kwargs)\n",
      "  File \"/lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py\", line 420, in call\n",
      "    return self._run_internal_graph(\n",
      "  File \"/lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py\", line 556, in _run_internal_graph\n",
      "    outputs = node.layer(*args, **kwargs)\n",
      "  File \"/lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1013, in __call__\n",
      "    input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n",
      "  File \"/lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/keras/engine/input_spec.py\", line 215, in assert_input_compatibility\n",
      "    raise ValueError('Input ' + str(input_index) + ' of layer ' +\n",
      "ValueError: Input 0 of layer bn_data is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: (224, 448, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1323 test_function  *\n        return step_function(self, iterator)\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1314 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_strategy.py:678 _call_for_each_replica\n        return mirrored_run.call_for_each_replica(\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_run.py:104 call_for_each_replica\n        return _call_for_each_replica(strategy, fn, args, kwargs)\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_run.py:245 _call_for_each_replica\n        coord.join(threads)\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/training/coordinator.py:389 join\n        six.reraise(*self._exc_info_to_raise)\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/six.py:703 reraise\n        raise value\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/training/coordinator.py:297 stop_on_exception\n        yield\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_run.py:334 run\n        self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1307 run_step  **\n        outputs = model.test_step(data)\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1266 test_step\n        y_pred = self(x, training=False)\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1030 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py:420 call\n        return self._run_internal_graph(\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py:556 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/keras/engine/input_spec.py:215 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer bn_data is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: (224, 448, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1894/3658403035.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss    :'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1487\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1489\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1490\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3020\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m-> 3022\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m/lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3439\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 3440\u001b[0;31m             return self._define_function_with_shape_relaxation(\n\u001b[0m\u001b[1;32m   3441\u001b[0m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3360\u001b[0m           expand_composites=True)\n\u001b[1;32m   3361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3362\u001b[0;31m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[1;32m   3363\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[1;32m   3364\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3279\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1323 test_function  *\n        return step_function(self, iterator)\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1314 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_strategy.py:678 _call_for_each_replica\n        return mirrored_run.call_for_each_replica(\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_run.py:104 call_for_each_replica\n        return _call_for_each_replica(strategy, fn, args, kwargs)\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_run.py:245 _call_for_each_replica\n        coord.join(threads)\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/training/coordinator.py:389 join\n        six.reraise(*self._exc_info_to_raise)\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/six.py:703 reraise\n        raise value\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/training/coordinator.py:297 stop_on_exception\n        yield\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_run.py:334 run\n        self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1307 run_step  **\n        outputs = model.test_step(data)\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1266 test_step\n        y_pred = self(x, training=False)\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1030 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py:420 call\n        return self._run_internal_graph(\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py:556 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/keras/engine/input_spec.py:215 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer bn_data is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: (224, 448, 3)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(val_ds.take(10).prefetch(tf.data.AUTOTUNE), verbose=0)\n",
    "\n",
    "print('Test loss    :', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e09a9df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-13 21:05:16.215624: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "/lustre_scratch/duncanwp/conda-envs/shiptrack-env/lib/python3.9/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
      "INFO:tensorflow:Assets written to: /lustre_scratch/duncanwp/models/20210713_174611_new_resnet152_bce_jaccard_loss/model/1/assets\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "# save Keras model for Tensorflow Serving\n",
    "\n",
    "tf.saved_model.save(\n",
    "    model,\n",
    "    os.path.join(model_dir, 'model/1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9eeb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(model_dir, 'model/2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4a0785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Shiptrack env",
   "language": "python",
   "name": "shiptrack-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
