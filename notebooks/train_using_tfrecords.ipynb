{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b737f62d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "     |████████████████████████████████| 1.4 MB 4.4 MB/s            \n",
      "\u001b[?25hCollecting segmentation-models\n",
      "  Using cached segmentation_models-1.0.1-py3-none-any.whl (33 kB)\n",
      "Collecting efficientnet==1.0.0\n",
      "  Using cached efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
      "Collecting keras-applications<=1.0.8,>=1.0.7\n",
      "  Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Collecting image-classifiers==1.0.0\n",
      "  Using cached image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.8/site-packages (from efficientnet==1.0.0->segmentation-models) (0.18.3)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.8/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.8/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.19.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.15.0)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.7.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.4.3)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.6.3)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (8.2.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.8/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2021.10.12)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.3.2)\n",
      "Installing collected packages: keras-applications, image-classifiers, efficientnet, segmentation-models, keras\n",
      "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-2.8.0 keras-applications-1.0.8 segmentation-models-1.0.1\n"
     ]
    }
   ],
   "source": [
    "! pip install keras segmentation-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d730bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-04 15:30:33.124935: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n",
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "from shiptrack import get_data, get_preprocessing, losses, fit_model\n",
    "from segmentation_models import get_preprocessing\n",
    "from segmentation_models import Unet, FPN\n",
    "from segmentation_models.metrics import iou_score\n",
    "import glob\n",
    "    \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "600dc364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "epochs = 100\n",
    "batch_size = 8\n",
    "learning_rate = 0.01\n",
    "augment = False\n",
    "encoder_freeze = False\n",
    "backbone = \"resnet152\"\n",
    "test_prop = 5\n",
    "loss = \"bce_jaccard_loss\"\n",
    "\n",
    "INT_IMG_SIZE = (2240, 1344)\n",
    "IMG_SIZE = 448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a58c07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "\n",
    "model_name = f\"{now.strftime('%Y%m%d_%H%M%S')}_new_{backbone}_{loss}{'_augmented' if augment else ''}\"\n",
    "# System paths\n",
    "training_dir = \"/lustre_scratch/duncanwp/combined_v3_typed_new_composite\"\n",
    "tensorboard_dir = f\"/lustre_scratch/duncanwp/tensorboard/{model_name}\"\n",
    "model_dir = f\"/lustre_scratch/duncanwp/models/{model_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7459d713",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 17:28:40.466813: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-10 17:28:40.467965: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-10 17:28:40.786248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:85:00.0 name: Tesla V100-SXM2-32GB-LS computeCapability: 7.0\n",
      "coreClock: 1.44GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 772.48GiB/s\n",
      "2021-12-10 17:28:40.790481: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:86:00.0 name: Tesla V100-SXM2-32GB-LS computeCapability: 7.0\n",
      "coreClock: 1.44GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 772.48GiB/s\n",
      "2021-12-10 17:28:40.790540: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-12-10 17:28:40.794474: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-12-10 17:28:40.794549: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-12-10 17:28:40.795838: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-10 17:28:40.796139: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-10 17:28:40.796893: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-10 17:28:40.797812: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-12-10 17:28:40.797989: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-12-10 17:28:40.819954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2021-12-10 17:28:40.820534: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-10 17:28:40.828699: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-10 17:28:41.219203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:85:00.0 name: Tesla V100-SXM2-32GB-LS computeCapability: 7.0\n",
      "coreClock: 1.44GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 772.48GiB/s\n",
      "2021-12-10 17:28:41.222378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:86:00.0 name: Tesla V100-SXM2-32GB-LS computeCapability: 7.0\n",
      "coreClock: 1.44GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 772.48GiB/s\n",
      "2021-12-10 17:28:41.222435: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-12-10 17:28:41.222482: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-12-10 17:28:41.222511: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-12-10 17:28:41.222538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-10 17:28:41.222564: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-10 17:28:41.222590: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-10 17:28:41.222616: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-12-10 17:28:41.222642: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-12-10 17:28:41.232486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2021-12-10 17:28:41.232555: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-12-10 17:28:42.321375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-10 17:28:42.321426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2021-12-10 17:28:42.321438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y \n",
      "2021-12-10 17:28:42.321446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N \n",
      "2021-12-10 17:28:42.338336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30094 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB-LS, pci bus id: 0000:85:00.0, compute capability: 7.0)\n",
      "2021-12-10 17:28:42.347041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 30094 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB-LS, pci bus id: 0000:86:00.0, compute capability: 7.0)\n"
     ]
    }
   ],
   "source": [
    "def create_mixed_dataset(training_dir, shuffle_size=1024, balance=None):\n",
    "# Balance should be a tuple of shape (2, ) describing the positive/negative weighting\n",
    "    positive = create_dataset(training_dir, shuffle_size=shuffle_size, cls_label='positive')\n",
    "    negative = create_dataset(training_dir, shuffle_size=shuffle_size, cls_label='negative')\n",
    "    if balance is None:\n",
    "        balance = (1.0, 0.0)\n",
    "    sampled_ds=tf.data.experimental.sample_from_datasets(datasets, weights=balance)\n",
    "    return sampled_ds\n",
    "\n",
    "# Note, if we wanted fewer classes, we can use glob syntax to grab multiple classes as once\n",
    "# e.g. create_dataset(2015,\"[67]\")\n",
    "# will take classes 6 & 7 together\n",
    "\n",
    "def _parse_batch(record_batch):\n",
    "    # Create a description of the features\n",
    "    feature_description = {\n",
    "        'data': tf.io.FixedLenFeature((IMG_SIZE, IMG_SIZE, 3), tf.float32),\n",
    "        'mask': tf.io.FixedLenFeature((IMG_SIZE, IMG_SIZE), tf.float32),\n",
    "    }\n",
    "\n",
    "    # Parse the input `tf.Example` proto using the dictionary above\n",
    "    example = tf.io.parse_example(record_batch, feature_description)\n",
    "    return example['data'], example['mask']\n",
    "\n",
    "\n",
    "def create_dataset(training_dir, shuffle_size=1024, cls_label='positive'):\n",
    "\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    fl = glob.glob(f\"/{training_dir}/tfrecords/*_{cls_label}.tfrecords\")\n",
    "    files_ds = tf.data.Dataset.list_files(fl)\n",
    "    ds = tf.data.TFRecordDataset(files_ds, num_parallel_reads=AUTOTUNE)\n",
    "    ds = ds.shuffle(shuffle_size)\n",
    "    ds = ds.map(lambda x: _parse_batch(x))\n",
    "    return ds\n",
    "\n",
    "\n",
    "ds_size = len(list(glob.glob(f\"/{training_dir}/tfrecords/*_positive.tfrecords\"))) # This assumes only taking positive examples\n",
    "ds = create_dataset(training_dir)\n",
    "\n",
    "train_split=0.8\n",
    "val_split=0.2\n",
    "# test_split=0.1\n",
    "train_size = int(train_split * ds_size)\n",
    "val_size = int(val_split * ds_size)\n",
    "\n",
    "train_ds = ds.take(train_size)    \n",
    "val_ds = ds.skip(train_size).take(val_size)\n",
    "# test_ds = ds.skip(train_size).skip(val_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "055d0e7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Automatically mirror training across all available GPUs\n",
    "strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
    "with strategy.scope():\n",
    "# TODO: I might want to explore without encoder weights again (especially if I get the augmentaiton working)\n",
    "# TODO: I could also explore the activations. 'swish' is a popular one but I'll need to renormalize my data first I think (-0.5)\n",
    "    model = Unet(backbone, encoder_weights='imagenet', encoder_freeze=encoder_freeze,\n",
    "                 classes=1, activation='sigmoid')\n",
    "\n",
    "#     print(model.summary())\n",
    "\n",
    "    model.compile(Adam(learning_rate=learning_rate), loss=losses[loss], metrics=[iou_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e10e07fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 17:28:52.809141: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2021-12-10 17:28:52.809190: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2021-12-10 17:28:52.809237: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 2 GPUs\n",
      "2021-12-10 17:28:52.809605: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcupti.so.11.0'; dlerror: libcupti.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.3/lib:/usr/local/cuda-11.3/lib64:/usr/local/cuda/compat\n",
      "2021-12-10 17:28:53.034022: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so\n",
      "2021-12-10 17:28:53.528191: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2021-12-10 17:28:53.537295: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard, ReduceLROnPlateau, ModelCheckpoint\n",
    "tensorboard = TensorBoard(log_dir=tensorboard_dir, histogram_freq=5,\n",
    "                          write_images=True, write_graph=False)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=5e-7, verbose=1)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=model_dir+'/model/checkpoint',\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "# TODO:\n",
    "# Add EarlyStopping and ModelCheckpoint callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84962794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_data_flow(data, labels, subset, batch_size=1):\n",
    "#     # this is the augmentation configuration we will use for training\n",
    "#     from keras.preprocessing.image import ImageDataGenerator\n",
    "#     datagen = ImageDataGenerator(\n",
    "#         shear_range=0.2,\n",
    "#         zoom_range=0.2,\n",
    "#         horizontal_flip=True,\n",
    "#         validation_split=0.2)\n",
    "#     generator = datagen.flow(\n",
    "#         data, y=labels,\n",
    "#         batch_size=batch_size if subset == 'training' else 1,\n",
    "#         subset=subset)\n",
    "#     return generator\n",
    "\n",
    "def get_data_flow(data, labels, subset, batch_size=1):\n",
    "    # we create two instances with the same arguments\n",
    "    data_gen_args = dict(\n",
    "                         shear_range=0.2,\n",
    "                         zoom_range=0.2,\n",
    "                         horizontal_flip=True,\n",
    "                        )\n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    # Provide the same seed and keyword arguments to the fit and flow methods\n",
    "    seed = 1\n",
    "    image_datagen.fit(data, augment=True, seed=seed)\n",
    "    mask_datagen.fit(labels, augment=True, seed=seed)\n",
    "    image_generator = image_datagen.flow(\n",
    "        data,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        seed=seed)\n",
    "    mask_generator = mask_datagen.flow(\n",
    "        labels,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        seed=seed)\n",
    "    # combine generators into one which yields image and masks\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    return train_generator\n",
    "\n",
    "def augment_images(image_label, seed):\n",
    "    image, label = image_label\n",
    "#     image, label = resize_and_rescale(image, label)\n",
    "#     image = tf.image.resize_with_crop_or_pad(image, IMG_SIZE + IMG_SIZE//20, IMG_SIZE + IMG_SIZE//20)\n",
    "#     label = tf.image.resize_with_crop_or_pad(label, IMG_SIZE + IMG_SIZE // 20, IMG_SIZE + IMG_SIZE // 20)\n",
    "    # Make a new seed\n",
    "    new_seed = tf.random.experimental.stateless_split(seed, num=1)[0, :]\n",
    "    # Random crop back to the original size\n",
    "#     image = tf.image.stateless_random_crop(image, size=[IMG_SIZE, IMG_SIZE, 3], seed=seed)\n",
    "#     label = tf.image.stateless_random_crop(label, size=[IMG_SIZE, IMG_SIZE], seed=seed)\n",
    "    # Random brightness\n",
    "#     image = tf.image.stateless_random_brightness(image, max_delta=0.5, seed=new_seed)  # (not the label for this one)\n",
    "    # Random flip\n",
    "    image = tf.image.stateless_random_flip_left_right(image, seed=new_seed)\n",
    "    label = tf.image.stateless_random_flip_left_right(label[..., tf.newaxis], seed=new_seed)[..., 0]\n",
    "    image = tf.image.stateless_random_flip_up_down(image, seed=new_seed)\n",
    "    label = tf.image.stateless_random_flip_up_down(label[..., tf.newaxis], seed=new_seed)[..., 0]\n",
    "#     image = tf.clip_by_value(image, 0, 1)  # Why would I do this?\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "888a212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def visualize(original, augmented):\n",
    "#     fig = plt.figure()\n",
    "#     plt.subplot(1,2,1)\n",
    "#     plt.title('Original image')\n",
    "#     plt.imshow(original)\n",
    "\n",
    "#     plt.subplot(1,2,2)\n",
    "#     plt.title('Augmented image')\n",
    "#     plt.imshow(augmented)\n",
    "\n",
    "# small_test, = test_ds.take(1)\n",
    "# for i in range(3):\n",
    "#     seed = (i, 0)\n",
    "#     augmented_image, augmented_label = augment_images(small_test, seed)\n",
    "#     print(augmented_label.shape)\n",
    "#     visualize(small_test[0], augmented_image)\n",
    "#     visualize(small_test[1], augmented_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4528085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if augment:\n",
    "#     raise NotImplemented()\n",
    "    counter = tf.data.experimental.Counter()\n",
    "    train_ds = tf.data.Dataset.zip((train_ds, (counter, counter))).map(augment_images, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e0e155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 17:28:53.737924: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-12-10 17:28:53.739609: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2195205000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 492 all-reduces with algorithm = hierarchical_copy, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 492 all-reduces with algorithm = hierarchical_copy, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 17:30:56.737864: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-12-10 17:31:02.016145: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-12-10 17:31:02.698224: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1/Unknown - 133s 133s/step - loss: 1.8987 - iou_score: 0.0123"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 17:31:06.861139: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2021-12-10 17:31:06.861188: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2/Unknown - 135s 2s/step - loss: 1.8204 - iou_score: 0.0132  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 17:31:09.265637: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
      "2021-12-10 17:31:09.298294: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed\n",
      "2021-12-10 17:31:09.802956: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:228]  GpuTracer has collected 7056 callback api events and 7044 activity events. \n",
      "2021-12-10 17:31:10.168109: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2021-12-10 17:31:10.574128: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /lustre_scratch/duncanwp/tensorboard/20211210_172840_new_resnet152_bce_jaccard_loss/train/plugins/profile/2021_12_10_17_31_10\n",
      "2021-12-10 17:31:10.724311: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to /lustre_scratch/duncanwp/tensorboard/20211210_172840_new_resnet152_bce_jaccard_loss/train/plugins/profile/2021_12_10_17_31_10/jupyter-duncanwp.trace.json.gz\n",
      "2021-12-10 17:31:11.172199: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /lustre_scratch/duncanwp/tensorboard/20211210_172840_new_resnet152_bce_jaccard_loss/train/plugins/profile/2021_12_10_17_31_10\n",
      "2021-12-10 17:31:11.197943: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to /lustre_scratch/duncanwp/tensorboard/20211210_172840_new_resnet152_bce_jaccard_loss/train/plugins/profile/2021_12_10_17_31_10/jupyter-duncanwp.memory_profile.json.gz\n",
      "2021-12-10 17:31:11.233985: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /lustre_scratch/duncanwp/tensorboard/20211210_172840_new_resnet152_bce_jaccard_loss/train/plugins/profile/2021_12_10_17_31_10Dumped tool data for xplane.pb to /lustre_scratch/duncanwp/tensorboard/20211210_172840_new_resnet152_bce_jaccard_loss/train/plugins/profile/2021_12_10_17_31_10/jupyter-duncanwp.xplane.pb\n",
      "Dumped tool data for overview_page.pb to /lustre_scratch/duncanwp/tensorboard/20211210_172840_new_resnet152_bce_jaccard_loss/train/plugins/profile/2021_12_10_17_31_10/jupyter-duncanwp.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to /lustre_scratch/duncanwp/tensorboard/20211210_172840_new_resnet152_bce_jaccard_loss/train/plugins/profile/2021_12_10_17_31_10/jupyter-duncanwp.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to /lustre_scratch/duncanwp/tensorboard/20211210_172840_new_resnet152_bce_jaccard_loss/train/plugins/profile/2021_12_10_17_31_10/jupyter-duncanwp.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to /lustre_scratch/duncanwp/tensorboard/20211210_172840_new_resnet152_bce_jaccard_loss/train/plugins/profile/2021_12_10_17_31_10/jupyter-duncanwp.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 305s 640ms/step - loss: nan - iou_score: 0.0122 - val_loss: 1.1181 - val_iou_score: 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 17:34:37.054255: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /lustre_scratch/duncanwp/models/20211210_172840_new_resnet152_bce_jaccard_loss/model/checkpoint/assets\n",
      "Epoch 2/100\n",
      "  6/270 [..............................] - ETA: 2:10 - loss: 1.0650 - iou_score: 0.0156"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds.shuffle(1024).batch(8*2).prefetch(tf.data.AUTOTUNE), validation_data=val_ds.batch(8).prefetch(tf.data.AUTOTUNE), verbose=1,\n",
    "                    epochs=epochs, callbacks=[tensorboard, reduce_lr, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785636e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = model.evaluate(test_ds.batch(8).prefetch(tf.data.AUTOTUNE), verbose=0)\n",
    "\n",
    "# print('Test loss    :', score[0])\n",
    "# print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e0e90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "# save Keras model for Tensorflow Serving\n",
    "\n",
    "tf.saved_model.save(\n",
    "    model,\n",
    "    os.path.join(model_dir, 'model/1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9388a3d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
