{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install 'sagemaker[local]' 'docker' --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.local import LocalSession\n",
    "\n",
    "# sagemaker_session = LocalSession()\n",
    "# sagemaker_session.config = {'local': {'local_code': True}}\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow.serving import Model\n",
    "\n",
    "model_path = 's3://sagemaker-us-east-2-280662875630/sagemaker-tensorflow-scriptmode-2020-04-30-17-58-04-177/output/model.tar.gz'\n",
    "\n",
    "model = Model(model_data=model_path, role=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_predictor = model.deploy(initial_instance_count=1, instance_type='local_gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "#tf_predictor = model.deploy(initial_instance_count=1,\n",
    "#                                   instance_type='ml.p2.xlarge')      # $1.361/hour in eu-west-1\n",
    "\n",
    "tf_predictor = model.deploy(initial_instance_count=1,\n",
    "                         instance_type='ml.c5.large',        # $0.134/hour in eu-west-1\n",
    "                         accelerator_type='ml.eia1.medium',  # + $0.140/hour in eu-west-1\n",
    "                         endpoint_name='shiptrack-detection')\n",
    "#                          serializer=npy_serializer, deserializer=numpy_deserializer)     # = 80% discount!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf_predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a825a999af34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tf_predictor' is not defined"
     ]
    }
   ],
   "source": [
    "# tf_predictor.content_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This doesn't seem to work but I don't know why...\n",
    "# from sagemaker.predictor import npy_serializer, numpy_deserializer\n",
    "\n",
    "# tf_predictor.serializer = npy_serializer\n",
    "# tf_predictor.deserializer = numpy_deserializer\n",
    "# tf_predictor.content_type = npy_serializer.content_type\n",
    "# tf_predictor.accept = npy_serializer.content_type\n",
    "\n",
    "# I think this is the preffered way to do it: https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html#create-python-scripts-for-custom-input-and-output-formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.tensorflow import TensorFlowPredictor\n",
    "from sagemaker.predictor import RealTimePredictor\n",
    "\n",
    "# predictor = TensorFlowPredictor('shiptrack-detection')\n",
    "tf_predictor = RealTimePredictor('shiptrack-detection')\n",
    "# result = predictor.predict(['my request body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# normalise = lambda data: [(d - mean_data)/std_data for d in data]\n",
    "# normalise = lambda data: (data - 0.5)/0.25\n",
    "normalise = lambda data: [(d - 0.45)/0.25 for d in data]\n",
    "\n",
    "def split_array(arr, step_size=440):\n",
    "    x_len, y_len = arr.shape[0:2]\n",
    "    x_split_locs = range(step_size, x_len, step_size)\n",
    "    y_split_locs = range(step_size, y_len, step_size)\n",
    "    v_splits = np.array_split(arr, x_split_locs, axis=0)\n",
    "    return sum((np.array_split(v_split, y_split_locs, axis=1) for v_split in v_splits), [])\n",
    "\n",
    "\n",
    "def process_typed_file(f_key, image_size, path=None, resize=False, channel=None):\n",
    "    import boto3\n",
    "    from PIL import ImageOps, Image\n",
    "    from io import BytesIO\n",
    "\n",
    "\n",
    "    s3 = boto3.client('s3')\n",
    "    file_byte_string = s3.get_object(Bucket='imiracli-data', Key=f_key)['Body'].read()\n",
    "\n",
    "    im_data = Image.open(BytesIO(file_byte_string))\n",
    "    if (im_data.size[1] not in [2030, 2040]) or (im_data.size[0] != 1354):\n",
    "        print(\"Skipping wierd shape: {}\".format(im_data.size))\n",
    "        raise ValueError()\n",
    "    \n",
    "    original_shape = im_data.size\n",
    "    \n",
    "    if resize:\n",
    "        im_data = im_data.resize(image_size, resample=Image.BILINEAR)\n",
    "        padding = 0\n",
    "    else:  # Pad\n",
    "        # expand by 160, 80 on each side\n",
    "        padding = 85 if im_data.size[1] == 2030 else 80\n",
    "        im_data = ImageOps.expand(im_data, padding)\n",
    "\n",
    "    # Drop the end of the y axis\n",
    "    im_data = np.array(im_data)#[:, :1320, :]\n",
    "    \n",
    "    if channel is not None:\n",
    "        im_data = im_data[..., channel]\n",
    "\n",
    "    return im_data, original_shape\n",
    "\n",
    "\n",
    "def combine_and_resize_masks(masks, original_size):\n",
    "    print(masks.shape)\n",
    "    # TODO: Make the nesting a parameter\n",
    "    nested_masks = [np.split(m, 5) for m in np.split(masks[..., 0], 8, 0)]\n",
    "#     print(len(nested_masks))\n",
    "#     print(nested_masks[0][0].shape)\n",
    "#     nested_masks = np.reshape(masks, (5, 8))\n",
    "    \n",
    "    mask = np.squeeze(np.block(nested_masks))\n",
    "#     print(mask.shape)\n",
    "    print(mask.any())\n",
    "    mask_im = Image.fromarray(mask)\n",
    "\n",
    "    mask_im = mask_im.resize(original_size, resample=Image.NEAREST)\n",
    "\n",
    "    # Don't forget to pop off the superfluous color dimension\n",
    "    new_mask = np.array(mask_im)#[:, :, 0]\n",
    "    \n",
    "    return new_mask\n",
    "\n",
    "\n",
    "def get_ship_track_mask(f):\n",
    "    data, original_shape = process_typed_file(f, (448*4, 448*3), resize=True)\n",
    "    norm_data = normalise(data)\n",
    "    print(original_shape)\n",
    "    print(data.shape)\n",
    "\n",
    "    split_data = normalise(split_array(np.concatenate([data[..., 0:1]/255.]*3, axis=-1), 448))\n",
    "    # Normalise? Anythinf else?\n",
    "#     print(split_data[0].shape)\n",
    "    stacked_data = np.stack(split_data)\n",
    "    print(stacked_data.shape)\n",
    "\n",
    "    d = stacked_data[0:1,...] #.tolist()\n",
    "    print(d)\n",
    "    pred = tf_predictor.predict(data=d.tobytes())\n",
    "    print(pred)\n",
    "    prediction = np.array(pred['predictions'])\n",
    "    \n",
    "#     for p in prediction:\n",
    "#         fig, axs = plt.subplots(figsize=(10, 20))\n",
    "#         axs.imshow(data[..., 0])\n",
    "#         axs.imshow(p[:,:, 0], alpha=0.5)\n",
    "#         plt.show()\n",
    "#     print(prediction.any())\n",
    "#     print(prediction.shape)\n",
    "    combined_prediction = combine_and_resize_masks(prediction, original_shape)\n",
    "    \n",
    "    combined_data = combine_and_resize_masks(np.stack(split_data), original_shape)\n",
    "    \n",
    "#     print(combined_data.shape)\n",
    "#     print(combined_prediction.any())\n",
    "#     print(combined_prediction)\n",
    "    if combined_prediction.any():\n",
    "        fig, axs = plt.subplots(figsize=(20, 40))\n",
    "        axs.imshow(combined_data[...], vmin=-2, vmax=2)\n",
    "        im=axs.imshow(combined_prediction[:,:], alpha=0.5, vmin=0, vmax=1)\n",
    "#         plt.colorbar(im)\n",
    "        plt.show()\n",
    "    return combined_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1354, 2030)\n",
      "(1344, 1792, 2)\n",
      "(12, 448, 448, 3)\n",
      "[[[[ 0.03529412  0.03529412  0.03529412]\n",
      "   [-0.35686275 -0.35686275 -0.35686275]\n",
      "   [-0.63921569 -0.63921569 -0.63921569]\n",
      "   ...\n",
      "   [ 0.20784314  0.20784314  0.20784314]\n",
      "   [ 0.23921569  0.23921569  0.23921569]\n",
      "   [ 0.31764706  0.31764706  0.31764706]]\n",
      "\n",
      "  [[ 0.30196078  0.30196078  0.30196078]\n",
      "   [-0.23137255 -0.23137255 -0.23137255]\n",
      "   [-0.65490196 -0.65490196 -0.65490196]\n",
      "   ...\n",
      "   [ 0.09803922  0.09803922  0.09803922]\n",
      "   [ 0.34901961  0.34901961  0.34901961]\n",
      "   [ 0.36470588  0.36470588  0.36470588]]\n",
      "\n",
      "  [[ 1.29019608  1.29019608  1.29019608]\n",
      "   [ 1.03921569  1.03921569  1.03921569]\n",
      "   [ 0.94509804  0.94509804  0.94509804]\n",
      "   ...\n",
      "   [-0.02745098 -0.02745098 -0.02745098]\n",
      "   [ 0.23921569  0.23921569  0.23921569]\n",
      "   [ 0.20784314  0.20784314  0.20784314]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 1.05490196  1.05490196  1.05490196]\n",
      "   [ 1.16470588  1.16470588  1.16470588]\n",
      "   [ 1.11764706  1.11764706  1.11764706]\n",
      "   ...\n",
      "   [-1.21960784 -1.21960784 -1.21960784]\n",
      "   [-1.26666667 -1.26666667 -1.26666667]\n",
      "   [-1.28235294 -1.28235294 -1.28235294]]\n",
      "\n",
      "  [[ 1.19607843  1.19607843  1.19607843]\n",
      "   [ 1.2745098   1.2745098   1.2745098 ]\n",
      "   [ 1.29019608  1.29019608  1.29019608]\n",
      "   ...\n",
      "   [-1.32941176 -1.32941176 -1.32941176]\n",
      "   [-1.39215686 -1.39215686 -1.39215686]\n",
      "   [-1.40784314 -1.40784314 -1.40784314]]\n",
      "\n",
      "  [[ 1.03921569  1.03921569  1.03921569]\n",
      "   [ 1.14901961  1.14901961  1.14901961]\n",
      "   [ 1.22745098  1.22745098  1.22745098]\n",
      "   ...\n",
      "   [-1.40784314 -1.40784314 -1.40784314]\n",
      "   [-1.45490196 -1.45490196 -1.45490196]\n",
      "   [-1.48627451 -1.48627451 -1.48627451]]]]\n"
     ]
    },
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (415) from model with message \"{\"error\": \"Unsupported Media Type: Unknown\"}\". See https://us-east-2.console.aws.amazon.com/cloudwatch/home?region=us-east-2#logEventViewer:group=/aws/sagemaker/Endpoints/shiptrack-detection in account 280662875630 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d797a2ad0b37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"images/MYD021KM.A2006166.1845.061.2018022234106.png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ship_track_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MODIS_deep_cloud/test_niremi_inference_images/images/MYD021KM.A2006166.1845.061.2018022234106.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-c3c6fd52607a>\u001b[0m in \u001b[0;36mget_ship_track_mask\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstacked_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#.tolist()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predictions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, initial_args, target_model)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mrequest_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_request_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_runtime_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    315\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (415) from model with message \"{\"error\": \"Unsupported Media Type: Unknown\"}\". See https://us-east-2.console.aws.amazon.com/cloudwatch/home?region=us-east-2#logEventViewer:group=/aws/sagemaker/Endpoints/shiptrack-detection in account 280662875630 for more information."
     ]
    }
   ],
   "source": [
    "data_path = 's3://imiracli-data/MODIS_deep_cloud/test_niremi_inference_images/'\n",
    "file_path = data_path+\"images/MYD021KM.A2006166.1845.061.2018022234106.png\"\n",
    "\n",
    "arr = get_ship_track_mask(\"MODIS_deep_cloud/test_niremi_inference_images/images/MYD021KM.A2006166.1845.061.2018022234106.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(tf_estimator.model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_samples = 5\n",
    "indices = random.sample(range(x_val.shape[0] - 1), num_samples)\n",
    "images = x_val[indices]/255\n",
    "labels = y_val[indices]\n",
    "\n",
    "for i in range(num_samples):\n",
    "    plt.subplot(1,num_samples,i+1)\n",
    "    plt.imshow(images[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(labels[i])\n",
    "    plt.axis('off')\n",
    "    \n",
    "prediction = tf_predictor.predict(images.reshape(num_samples, 28, 28, 1))['predictions']\n",
    "prediction = np.array(prediction)\n",
    "predicted_label = prediction.argmax(axis=1)\n",
    "print('Predicted labels are: {}'.format(predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_endpoint(endpoint_name='shiptrack-detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
